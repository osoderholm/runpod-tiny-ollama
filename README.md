# runpod-tiny-ollama

Ready to use Runpod Serverless container for running `tinyllama` using Ollama.

The `tinyllama` is already pulled, making the Docker image larger but shortening the startup time.
